\section{Background}
\subsection{State Model Inference}
Roughly speaking, EFSM\footnote{Extended Finite State Machines, are special kind of state machines that have conditional expressions called `transition guards' on their transitions. A state transition can only happen if the transition guard evaluates true.} inference algorithms generally take a list of `events` (along with some variable values) as the input \cite{walkinshaw2016inferring}. They use the events to find the state transitions and the values for detecting invariants and generating guard  conditions for the transitions. 

\subsection{Change Point Detection}
A fundamental tool in time series data analysis is Change Point Detection (CPD). It refers to the task of finding when the model generating the values has changed. 
They can generally be categorized into two main groups: online methods that process the data in real time and offline methods that start processing the data after receiving all the values  \cite{Truong2018ChangePointSurvey}. 
In this paper we only look at offline approaches to stay relevant.


This problem has been tackled from various perspectives. There are hundreds of papers in the literature contributing in this widely used field over the past decades. \cite{chen2011parametric, hasan2014information, hsu1982bayesian, lee2017implicit, oh2002analyzing, ramos2016anomalies, reeves2007review, rosenfield2010change, wang2011non, xie2013sequential, yamanishi2004line, Lavielle1999} Bayesian models focus on finding changes in parameters of underlying distributions generating the data \cite{Lee2018TimeSeriesSegmentation, adams2007bayesian, bai1997estimation, barry1993bayesian, erdman2008fast, ray2002bayesian}. Several methods have used penalty function based methods to find models best fitting each segment of the signals \cite{Lavielle1999, lavielle2005using, keshavarz2018optimal, pein2017heterogeneous}. With a slight change in the penalty function, they are usually usable for detecting known and unknown number of change points. 

Ives and Dakos utilized locally linear models and used statistical significance test to determine at which point the changes in model parameters are large enough to signal a change in the state \cite{Ives2012}. Blythe et al used subspace analysis to reduce data dimensionality to keep the most non-stationary dimensions. This process helps detecting change points more effectively \cite{Blythe2012}. 
%The review: \cite{Truong2018ChangePointSurvey}



\subsection{Deep Learning}
Deep neural networks have shown great 

CNNs

RNNs

Hybrid networks

. DeepSense \cite{deepsense}: Detects the state of mobile user based on sensor input such as accelerometer  \\
. Wearable moltimodal phase \cite{Ordonez2016}\\
. Survey \cite{wang2019deep} 4.6 for CNN-RNN Hybrid related work\\
.. CNN + Dense RNN $>>>$ CNN + Dense \cite{morales2016deep}\\
.. Similar conclusion in \cite{singh2017transforming}\\
.. DRNN outperforms CNNs and DBN (Deep believe networks) \cite{murad2017deep} Also Section 3 presents a background overview of RNNs and LSTM.\\
.. \cite{zheng2016exploiting}\\
